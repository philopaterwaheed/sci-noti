# Quick Reference Card

## ğŸš€ Quick Start Commands

### Setup (One-time)
```bash
# Install dependencies
pip install -r requirements.txt

# Configure Kaggle API
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

### Download & Clean FER2013 (One Command)
```bash
python fer2013_cleaner.py --full
```
Output: `data/fer2013/fer2013_cleaned.npz` (~70-85% of original data, highest quality)

## ğŸ“Š Main Scripts

| Script | Purpose | Usage |
|--------|---------|-------|
| `fer2013_cleaner.py` | FER2013 download & cleaning | `python fer2013_cleaner.py --full` |
| `kaggle_data_fetcher.py` | Multi-dataset downloader | `python kaggle_data_fetcher.py --list` |
| `data_cleaner.py` | General cleaning module | Import in Python |
| `example_usage.py` | Usage examples | `python example_usage.py` |

## ğŸ”§ Common Commands

```bash
# List available Kaggle datasets
python kaggle_data_fetcher.py --list

# Download only FER2013
python fer2013_cleaner.py --download

# Clean existing data
python fer2013_cleaner.py --clean --enhance --save

# Download multiple datasets
python kaggle_data_fetcher.py --datasets fer2013 ck_plus raf_db

# Run examples
python example_usage.py
```

## ğŸ Python Quick Start

```python
from fer2013_cleaner import FER2013Cleaner

# Full pipeline
cleaner = FER2013Cleaner(data_dir='./data')
images, labels = cleaner.full_pipeline()

# Now train your model
from tensorflow.keras.utils import to_categorical
y = to_categorical(labels, num_classes=7)
X = images.astype('float32') / 255.0
X = X[..., np.newaxis]
# model.fit(X, y, ...)
```

## ğŸ““ Jupyter Notebook

1. Open `ultra_improved_emotion_model_(6).ipynb` in Google Colab
2. Upload `kaggle.json` when prompted
3. Run all cells â†’ Automatic download, clean, and train!

## âš™ï¸ Customization

```python
from data_cleaner import FacialExpressionDataCleaner

cleaner = FacialExpressionDataCleaner(
    blur_threshold=80,           # Higher = stricter (default: 80)
    brightness_range=(40, 220),  # Wider = more permissive (default: 40-220)
    min_face_ratio=0.30,         # Face size minimum (default: 0.30)
    outlier_std_multiplier=2.5   # Lower = more aggressive (default: 2.5)
)

clean_X, clean_y = cleaner.clean_dataset(
    images=X,
    labels=y,
    use_face_detection=False,    # Set True to enable (requires mtcnn)
    use_embeddings=False,        # Set True to enable (requires insightface)
    use_clahe=True,              # Recommended: always True
    verbose=True
)
```

## ğŸ“ˆ Expected Results

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Dataset size | 35,887 | ~25,000-30,000 | Removes 15-30% poor quality |
| Validation accuracy | 65-68% | 70-74% | **+2-5%** |
| Training stability | Variable | Stable | Faster convergence |
| Data quality | Mixed | High | 70-85% retention of best |

## ğŸ§¹ Cleaning Pipeline

**Stage 1: Quality Filters**
- âœ“ Blur detection (Laplacian variance > 80)
- âœ“ Brightness (40 < mean < 220)
- âœ“ Contrast (std > 20)
- âœ“ Occlusion (edge density check)

**Stage 2: Advanced (Optional)**
- âœ“ Face detection (MTCNN)
- âœ“ Outlier removal (InsightFace)

**Stage 3: Enhancement**
- âœ“ CLAHE contrast improvement

## ğŸ” Troubleshooting

| Issue | Solution |
|-------|----------|
| "Kaggle not found" | `pip install kaggle` |
| "Credentials not found" | Setup kaggle.json in ~/.kaggle/ |
| "Too much removed" | Lower blur_threshold, widen brightness_range |
| "MTCNN not found" | `pip install mtcnn` or set use_face_detection=False |
| "InsightFace error" | `pip install insightface` or set use_embeddings=False |

## ğŸ“š Documentation

- **README.md** - Project overview and features
- **USAGE_GUIDE.md** - Complete step-by-step guide (11 KB)
- **IMPROVEMENTS_SUMMARY.md** - Technical details (10 KB)
- **example_usage.py** - Working code examples
- **This file** - Quick reference

## ğŸ’¡ Tips

âœ… Always use FER2013 as primary dataset  
âœ… Start with basic cleaning before advanced features  
âœ… Save cleaned data to avoid re-processing  
âœ… Use CLAHE enhancement (no downsides)  
âœ… Monitor per-class accuracy to detect bias  
âœ… Test with/without cleaning to measure impact  

## ğŸ¯ Common Workflows

### Research/Experimentation
```bash
python fer2013_cleaner.py --full
# Train model with cleaned data
# Compare with baseline
```

### Production
```python
# Load pre-cleaned data
data = np.load('data/fer2013/fer2013_cleaned.npz')
X, y = data['images'], data['labels']
# Train production model
```

### Custom Dataset
```python
from data_cleaner import FacialExpressionDataCleaner
cleaner = FacialExpressionDataCleaner()
clean_X, clean_y = cleaner.clean_dataset(my_images, my_labels)
```

---

**Quick Help**: `python fer2013_cleaner.py --help`  
**Examples**: `python example_usage.py`  
**Full Guide**: See USAGE_GUIDE.md
